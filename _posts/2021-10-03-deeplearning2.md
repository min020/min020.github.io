---
layout: post
title: "기계학습"
excerpt: "기계학습 작업흐름"
category: deep_learning
date: 2021-10-30
last_modified_at: 2021-10-30
use_math: true
---

# 기계학습의 보편적인 작업 흐름

우리는 지금까지 `keras.datasets`에서 레이블이 모두 준비되어 있는 데이터셋을 통해 바로 딥러닝 모델을 학습시켰다. 하지만 실제 문제를 해결할 때에는 데이터셋이 아니라 아무것도 갖춰진 것이 없는 문제서부터 출발해야 한다.

기계학습의 보편적인 작업 흐름은 크게 세 부분으로 구성된다.
+ 문제 정의 : 데이터셋을 수집하고 데이터가 나타내는 것을 이해한 후 문제를 성공적으로 측정할 수 있는 방안을 선택한다.
+ 모델 개발 : 데이터 전처리 과정을 거치고 모델 평가 방식과 간단한 기준선을 정한 후 일반화 성능을 갖춘 첫 모델을 훈련시킨다음 정규화하고 조절한다.
+ 모델 구축 : 모델을 사용할 플렛폼에 적용시키고 실전에서의 성능을 모니터링 한다. 그리고 다음 세대 모델 구축에 필요한 데이터 수집을 한다.

<br/>

## 1. 문제 정의

어떤 종류의 데이터를 이용하거나 수집해야 하는지, 어떤 종류의 기계학습 문제를 실무 문제에 대입시킬 수 있는지 등 해결하고자 하는 문제를 깊이 이해하지 않고서는 원활하게 해결할 수 없다.

<br/>

### 1.1 문제의 틀 잡기

+ 일반적으로 데이터의 가용은 제한적이기 때문에 대부분 사용자가 직접 데이터셋을 수집하고 주석을 달아야 한다.
+ 어떤 종류의 문제를 해결해야 하는지 파악해야 올바른 방법을 선택할 수 있다.
+ 기존에 만들어져 있는 솔루션이 있다면 어떤 것이 구축되어 있는지, 어떻게 작동하는지 이해해야 한다.
+ 문제에 대한 솔루션을 적용할 때 처리해야 할 특별한 제약이 있는지 전체적인 맥락을 파악해야 한다.

다음 가정을 주의해야 한다.
+ input이 주어지면 target을 예측할 수 있다.
+ 데이터가 input과 target간의 관계를 학습하는데 충분한 정보를 제공한다.

모델이 갖춰지기 전까지는 해당 가정이이 사실인지 거짓인지 알 수 없기 때문에 위 내용을 유의하지 않으면 문제 해결을 성공할 가능성이 낮다.

<br/>

### 1.2 데이터 수집

문제의 특성을 이해하고 input과 target이 무엇인지 이해하게 되었으면 이제 가장 시간과 비용이 많이 드는 데이터 수집이 필요한 시점이다.

모델의 일반화 기능은 전적으로 학습된 데이터의 속성(데이터 특징의 수, 레이블의 신뢰성, 특성의 품질)에서 비롯된다. 따라서 프로젝트에 시간을 더 할애할 경우 모델의 개선사항을 검색하는 것보다는 더 많은 데이터를 수집하는 것이 효과적인 방법이다.

알고리즘보다 데이터가 더 중요하다는 것은 2009년 구글 연구진의 논문 "The Unreasonable Effectiveness of Data"에서 부터 유명해 졌다. 이때는 딥러닝이 대중화 되기 전이었지만 이후 딥러닝의 부상은 데이터의 중요성을 더 부각시켰다.

지도학습을 수행할 경우 데이터를 수집한 후 모델이 예측하도록 훈련시킬 주석이 필요하다. 애초에 주석이 있는 경우도 있지만 직접 주석을 다는 경우가 대다수다. 

__데이터 주석화에 대한 투자__

데이터 주석화의 과정에 따라 target의 품질이 결정되고 이는 모델의 품질에도 영향을 준다. 즉 문제를 해결하기 위한 작업의 제약 조건을 고려하여 주석화에 사용할 수 있는 옵션을 신중히 선택해야 한다. 소프트웨어를 사용해서 주석화를 진행할 경우 많은 시간을 절약할 수 있기 때문에 프로젝트 초기에 투자할 가치가 있다.

__대표하지 않는 데이터__

모델은 이전에 학습한 데이터와 비슷한 데이터만 이해할 수 있다. 따라서 훈련에 사용되는 데이터가 앞으로 생산되는 데이터를 대표해야 한다.

되도록이면 데이터는 직접 모델이 사용될 환경에서 수집해야 한다. 그렇지 않으면 훈련 데이터와 실제 예측에 사용되는 데이터의 차이로 인해 모델이 정상적으로 작동되지 않을 수 있기 때문이다.

concept drift라는 개념을 이해할 필요가 있다. concept drift는 거의 모든 문제, 특히 사용자가 생성하는 데이터를 다루는 문제에서 발생하는데 시간이 지날수록 데이터의 속성에 변화가 생겨 예측 모델의 정확도가 떨어지는 현상을 말한다. concept drift를 해결하기 위해서는 지속적인 데이터 수집, 주석화 및 모델의 재훈련이 필요하다.

대표하지 않는 데이터를 수집하는 흔한 경우는 표본 편향 문제이다. 표본 편향 문제는 예측하려는 것과 연관지어 데이터를 수집할 때 발생한다. 

<br/>

### 1.3 데이터 이해하기

데이터셋을 블랙박스(원하는 결과를 도출할 수 있지만 어떤 근거로 결과가 나왔는지 모르는 것)로 취급하는 것은 좋지 않은 행동이다. 모델을 훈련시키기 전에 데이터가 어떤 패턴을 가지고 있는지 어떤 식으로 분포되어 있는지 등 충분히 탐색하고 시각화하여 예측 가능한 요소를 파악해야 한다. 또한 실제 운영 환경에서 주어지는 데이터가 훈련 데이터셋과 같은 형태로 제공되는지 파악해야 한다.

<br/>

### 1.4 문제 해결 성공의 기준 정하기

프로젝트를 성공하기 위해서는 어떤 기준이 성공인지를 정의해야 한다. 성공의 기준을 정해야 어떤 기술을 활용해야 하는지 감이 잡힐 것이다. 성공의 측정을 위해 사용자 지정 metrics를 정의해야 하는 경우도 있을 텐데 이럴 경우 다양한 문제와 평가 지표를 보여주는 Kaggle의 데이터 과학 대회를 살펴보면 도움이 많이 될 것이다.

<br/>
<br/>

## 2. 모델 개발

모델 개발 과정은 기계학습 작업 흐름에서 가장 어려운 과정이 아니다. 가장 어려운 과정은 데이터 수집 및 주석화, 전처리 과정이기 떄문에 모델 개발 과정은 상대적으로 쉬울 것이다.

<br/>

### 2.1 데이터 준비

데이터 전처리는 신경망이 원시 데이터를 잘 이용할 수 있도록 하는 것을 목표로 한다. 벡터화, 정규화, 결측값 처리 등이 있는데 전처리 과정은 데이터 형식에 따라 다르다. 하지만 지금은 모든 데이터 형식에 공통적으로 적용되는 사항만 살펴본다.

__벡터화__

신경망의 모든 input과 target은 부동소수점(특별한 경우 정수나 문자열)의 텐서 형식이어야 한다. 사운드, 이미지, 텍스트 등 어떤 데이터든 먼저 텐서로 전환해야 하며 이 과정을 벡터화라 한다.

__정규화__

MINST 예제에서는 0-255 범위로 인코딩 되어 있는 데이터를 float32로 캐스팅하고 255로 나눠 0-1범위로 정규화 시켰다. 일반적으로 상대적 큰 값이나 값의 범위가 많이 상이한 특성들을 가지고 있는 데이터를 사용하면 학습이 제대로 이뤄지지 않을 수 있다. 신경망이 쉽게 학습하기 위해서는 데이터에 다음과 같은 특징이 있어야 한다.
+ 작은 값으로 바꾸기 : 대부분 값의 범위가 0-1이어야 한다.
+ 균일화 : 모든 특성의 값이 거의 동일한 범위를 가져야 한다.

정규화는 다음과 같은 방법이 일반적으로 쓰인다.
+ 평균이 0이 되도록 한다.
+ 표준편차가 1이 되도록 한다.

__결측값 처리__

종종 데이터에 결측값이 있을 경우 반드시 삭제해야 하는 것은 아니다. 
+ 특성이 범주형인 경우 "값이 누락되었습니다"라는 범주를 새로 만드는 것이 좋다.
+ 특성이 수치인 경우 0과 같이 임의 값을 입력하면 안된다. 대신에 해당 특성에 대한 평균값이나 중앙값을 입력하는 것이 좋다. 또한 다른 특성의 값으로 해당 특성의 결측값을 예측하도록 할 수 있다.

만약 테스트 데이터에 결측값이 있을 것으로 예측되면 훈련 데이터에 테스트 데이터에서 결측값이 있을 것으로 예샹되는 특성에 일부러 결측값을 만들어 모델을 훈련시켜야 한다.

<br/>

### 2.2 평가 방식 선택

모델 개발의 목적은 일반화 시키는 것이며 검증 지표로 일반화 성능을 측정한다.
+ 홀드아웃 검증 세트 : 데이터가 충분한 경우
+ k-fold 교차 검증 : 샘플 수가 적어 홀드아웃 검증이 신뢰되지 않을 경우
+ 반복 k-fold 교차 검증 : 데이터가 매우 적을 경우

<br/>

### 2.3 기준 넘기

모델 자체에 대한 작업을 시작하면 초기 목표는 간단한 기준선을 넘는 작은 모델을 개발하는 것이다. 이 단계에서는 다음의 3가지 사항이 중요하다
+ 특성 엔지니어링 : 불필요한 특성을 제거하고 문제에 대한 지식을 활용해 다른 유용한 특성을 새로 만들 수 있다.
+ 올바른 모델 구조 선택 : 촘촘한 신경망, 반복적 신경망 등 올바른 구조를 선택해야 한다.
+ 올바른 학습 환경 선택 : 손실함수나 배치 크기, 학습률 등을 올바르게 선택해야 한다.

__손실함수__

|문제유형|활성함수|손실함수|
|--------|--------|--------|
|이진분류|sigmoid|binary_crossentropy|
|다중 클래스, 단일 레이블|softmax|categorical_crossentropy
|다중 클래스, 다중 레이블|sigmoid|binary_crossentropy|
|회귀|None|mse|

대부분 문제는 앞서 만들어져 있는 틀이 있다. 기존의 것을 조사해서 어떤 특성 엔지니어링과 모델 구조를 적용할지 살펴보는 것도 좋은 방법이다.

<br/>

### 2.4 과대적합 모델 개발

통계적으로 예측을 잘 해내는 모델을 만들어내면 과연 그 모델이 충분히 좋은 모델인가 하는 의문점이 들 수 있다. 이상적인 모델은 과소적합과 과대적합의 사이, 그리고 적절한 개수의 파라미터를 가지고 일반화가 잘 이뤄지는 모델이다. 그럼 이 이상적인 모델의 기준이 어디에 있는지 알기 위해서는 기준을 넘어야 한다. 과대적합 모델을 만들기 위해서는 다음 3가지를 수행하면 된다.
+ 레이어 추가
+ 층의 크기 키우기
+ 에포크 수 늘리기

<br/>

### 2.5 모델 정규화 및 조정

과대적합 모델을 만들었다면 이제는 일반화 성능을 높여야 하는 단계이다. 이 단계에서는 모델이 검증 데이터(지금 단계에서는 테스트셋을 사용하지 않음)에서 좋은 성능을 낼때까지 수정하고 검증하는 과정을 반복한다. 다음의 방법을 사용하면 효율적이다.
+ 다양한 모델 구조사용, 층을 추가하거나 삭제
+ dropout 적용
+ L1, L2 규제를 사용
+ 다양한 하이퍼 파라미터(ex:층마다 특성수)를 수정
+ 데이터 수집이나 주석화를 더 많이 수행, 더 유용한 특성을 만들거나 삭제

유의할 점은 만약 검증 과정의 결과를 이용해 모델을 조정하면 검증 데이터셋에 모델이 과대적합될 가능성이 있다. 테스트셋에서 평가를 시행했을 때 검증 데이터셋보다 성능이 많이 떨어진다면 검증 과정의 신뢰도가 많이 떨어졌음을 의미한다. 이 경우 k-fold 반복 검증을 사용하는 등 다른 검증 방식을 사용해야 한다.

<br/>
<br/>

## 3. 모델 구축

테스트 데이터셋에 대한 최종 평가를 마쳤으면 구축과 실전 투입만 남았다.

<br/>

### 3.1 사용자에게 작업 설명 및 기대치 설정

AI시스템의 비전문가들은 종종 AI가 문제에 대해 사람같이 생각하며 해결할 수 있을거라 생각한다. 이런 생각을 미연에 방지하기 위해 모델이 제대로 작동하지 않는 예제를 보여줘야 한다. 

대부분의 기계학습은 모델은 사람이 만든 라벨에 근접하도록 훈련됐기 때문에 완벽하게 도달하지는 못한다. "모델이 90%의 정확도를 가지고 있다."이렇게 말하면 사람들은 무의식적으로 최대 100%정도라 인식하기 때문에 추상적으로 말하기 보다는 거짓 양성 비율과 거짓 음성 비율 같이 구체적으로 말하는 것이 좋다. 

<br/>

### 3.2 추론 모델 내보내기

기계학습 프로젝트는 훈련된 모델을 Colab notebook에 저장한다고 끝나는 것이 아니다. 보통 훈련 과정동안 조작한 동일한 파이썬 객체 모델을 실제 운영에 그대로 적용하는 경우는 거의 없다. 따라서 먼저 모델을 파이썬이 아닌 다른 환경에 적용 시켜보는 것이 좋다.
+ 운영 환경이 파이썬을 지원하지 않을 수 있다.
+ 만약 다른 프로그램이 파이썬이 아닌 경우 모델을 사용하기 위해 파이썬을 사용할 경우 상당한 처리 시간이 소요될 수 있다.

두번째로 개발한 모델은 훈련 용도가 아니라 예측에만 사용되기 때문에 더 빠르고 메모리 사용을 줄일 수 있는 다양한 최적화를 실시할 수 있다.

<br/>

__REST API로 모델 배포__

아마 모델을 제품으로 바꾸는 일반적인 방법일 것이다. 서버나 클라우드 서버에 TensorFlow를 설치하고 REST API를 통해 모델의 예측을 질의하는 방법이다. 다음과 같은 경우 해당 설정을 사용한다.
+ 애플리케이션이 인터넷에 안정적으로 연결할 수 있을 때
+ 애플리케이션이 엄격한 대기 시간을 요구하지 않을 때
+ 입력 데이터가 민감하지 않아서 해독된 상태로 서버에서 사용할 수 있을 때

__장치에 모델 배포__

스마트폰, 내장형 ARM CPU 등 여러 장치에 모델을 사용해야 하는 경우가 있다. 다음과 같은 경우 해당 설정을 사용한다.
+ 지연 시간에 대해 엄격하거나 연결성이 낮은 환경에서 실행해야 할 때
+ 장치의 메모리 및 전력 제약 조건 때문에 모델을 작게 만들어야 할 때
+ GPU에서 실행할 수 있는 최상의 모델만큼은 아니지만 런타임의 효율성과 정확성 사이에 균형잡힌 모델을 제공해야 하는 경우
+ 입력 데이터가 민감하여 원격 서버에서 해독할 수 없을 때

__브라우저에서 모델 배포__

딥러닝은 브라우저 또는 데스크탑 기반 자바스크립트 응용 프로그램에서 자주 사용된다. 응용 프로그램이 REST API를 통해 원격으로 모델을 사용할 수도 있지만 사용자의 대스크탑에서 직접 모델을 실행할 수 있는 이점이 있다. 다음과 같은 경우 해당 설정을 사용한다.
+ 최종 사용자에게 오프로드(cpu가 TCP/IP프로세싱을 하지 않도록 하여 성능을 향상 시키는 것)하여 서버 비용을 절감할 수 있을 때
+ 입력 데이터가 최종 사용자의 장치에 남아 있어야 할 때
+ 애플리케이션에 엄격한 지연 시간 제약이 있을 때
+ 모델을 다운로드하고 연결 없이 계속 사용해야 할 때

모델이 사용자 장치의 CPU, GPU, 또는 RAM을 독점하지 않을 정도로 작은 경우에만 이 방법을 사용해야 한다. 

__추론 모델 최적화__

사용 가능한 전력 및 메모리에 엄격한 제약이 있는 환경이나 대기 시간이 짧은 애플리케이션에 배포할 때 모델을 최적화 하는 것이 특히 중요하다. 이때 적용할 수 있는 최적화 기법은 일반적으로 두 가지가 있다.
+ 가중치 다듬기 : 모든 가중치가 예측이 동일하게 기여하는 것은 아니다. 가장 중요한 가중치만 유지하면 모델의 층에서 매개변수의 수를 크게 줄일 수 있다. 따라서 적은 비용으로 모델의 메모리 사용 및 설치 용량을 줄일 수 있다.
+ 가중치 양자화 : 딥러닝 모델은 부동 소수점(float32) 가중치를 사용하여 훈련한다. 하지만 가중치를 8비트 정수(int8)로 양자화하면 4배 작지만 기존 모델의 정확도에 가까운 모델을 얻을 수 있다.

<br/>

### 3.3 실전 모니터링

모델을 구축한 후에는 모델의 동작, 새 데이터에 대한 성능, 다른 애플리케이션과의 상호 작용 등 계속 모니터링해야 한다.
+ 새로운 서비스가 기존 서비스에 비해 정말 효과가 있는지 확인한다.
+ 가능하면 생산되는 데이터에 대한 모델의 예측을 정기적으로 직접 검사한다. 새롭게 생산된 데이터의 일부에 수동으로 주석을 달고 모델에 전송하여 예측값을 새 주석과 비교해본다.
+ 직접 검사가 불가능한 경우, 사용자 설문 조사와 같은 대체 방법으로 평가해야 한다.

<br/>

### 3.4 모델 유지

위에서 concept drift라는 개념을 살펴봤듯이 시간이 지남에 따라 생산되는 데이터의 특성이 변경되어 모델의 성능은 점점 하락하게 된다. 따라서 모델을 출시하자마자 현재 모델을 대체할 다음 세대 모델을 교육할 준비를 해야한다.
+ 새로운 기능을 사용할 수 있는지, 레이블 세트를 늘려야 하는지 새로 생산되는 데이터의 변화에 주의해야 한다.
+ 데이터를 계속 수집하고 주석화를 해야하며 특히 현재 모델이 분류하기 어려워하는 표본을 수집해야 한다. 이런 표본은 모델의 성능을 향상시키는데 도움이 될 가능성이 높다.

<br/>
<br/>

## 4. 요약

+ 해결해야 할 문제를 정의한다.
 + 현재 징행 중인 작업의 맥락을 파악
 + 데이터를 수집하고 주석화하며 자세히 이해
 + 검증 데이터를 어떤 측정방법으로 모니터링 할 것인지 선택
+ 문제 이해 및 데이터를 확보하면 모델을 개발
 + 평가 방식 선택
 + 적절한 통계 능력 달성
 + 과대적합 모델 개발 후 검증 데이터의 성능에 따라 정규화
+ 테스트 데이터에 대해 우수한 성능을 보이면 모델 구축
 + 사용자의 적절한 기대치 설정
 + 최종 모델을 최적화 후 원하는 환경에 모델 배치
 + 모델 성능을 모니터링하고 데이터를 계속 수집하여 차세대 모델 개발
